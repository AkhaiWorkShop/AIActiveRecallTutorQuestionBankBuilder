import io
import re
import os
import logging
import numpy as np
from typing import Dict, Any, List
from PIL import Image
from paddleocr import PaddleOCR


os.environ["DISABLE_MODEL_SOURCE_CHECK"] = "True"

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

class ImagePreprocessor:
    @staticmethod
    def preprocess(image: Image.Image) -> np.ndarray:
        if image.mode != "RGB":
            image = image.convert("RGB")

        # upscale jika terlalu kecil
        if image.height < 900:
            scale = 900 / image.height
            image = image.resize(
                (int(image.width * scale), 900),
                Image.Resampling.LANCZOS
            )

        return np.array(image)

class OCRExtractor:
    def __init__(self):
        self.ocr = PaddleOCR(
            use_angle_cls=True,
            lang="id",
            show_log=False,
            det_db_thresh=0.3,
            det_db_box_thresh=0.3,
            drop_score=0.5
        )

    def extract_text(self, image_np: np.ndarray) -> tuple[str, float]:
        result = self.ocr.ocr(image_np)
        if not result or not result[0]:
            return "", 0.0

        blocks = []
        for line in result[0]:
            box, (text, conf) = line
            if conf >= 0.4:
                x_coords = [p[0] for p in box]
                y_coords = [p[1] for p in box]
                blocks.append({
                    "text": text.strip(),
                    "conf": conf,
                    "x": min(x_coords),
                    "y": min(y_coords),
                    "w": max(x_coords) - min(x_coords),
                    "h": max(y_coords) - min(y_coords)
                })

        if not blocks:
            return "", 0.0

        # Dynamic Column Detection
        xs = [b["x"] for b in blocks]
        min_x, max_x = min(xs), max(b["x"] + b["w"] for b in blocks)
        mid_p = min_x + (max_x - min_x) / 2
        avg_h = np.mean([b["h"] for b in blocks])
        
        # Group into columns
        # A block is in col1 if its center is left of mid_p
        col1 = [b for b in blocks if (b["x"] + b["w"]/2) < mid_p]
        col2 = [b for b in blocks if (b["x"] + b["w"]/2) >= mid_p]
        
        if len(col1) > 4 and len(col2) > 4:
            # Sort each column: Y (banded) then X
            col1.sort(key=lambda b: (b["y"] // (avg_h * 0.5), b["x"]))
            col2.sort(key=lambda b: (b["y"] // (avg_h * 0.5), b["x"]))
            sorted_blocks = col1 + col2
            logging.info(f"Two columns detected. Mid={mid_p}")
        else:
            sorted_blocks = sorted(blocks, key=lambda b: (b["y"] // (avg_h * 0.5), b["x"]))

        texts = [b["text"] for b in sorted_blocks]
        confidences = [b["conf"] for b in sorted_blocks]

        avg_conf = round(float(np.mean(confidences)), 3) if confidences else 0.0
        return "\n".join(texts), avg_conf

class TextNormalizer:
    @staticmethod
    def normalize_string(text: str) -> str:
        """Clean common OCR artifacts and normalize certain terms"""
        replacements = {
            "kalirnat": "kalimat", "daerali": "daerah", "Koi": "Kei",
            "Soio": "Solo", "Larnpung": "Lampung", "fa/behe": "falbehe",
            "daridaerah": "dari daerah", "kabheereh": "kabhoereh",
            "kali- mat": "kalimat", "daridaerah": "dari daerah",
            "Provinsi....": "Provinsi", "daridaerah...": "dari daerah"
        }
        for k, v in replacements.items():
            text = text.replace(k, v)
        
        # Split markers safely: only if at start of string/line or following a space
        # And require a punctuation mark (dot or paren) to avoid splitting words like "Madura"
        text = re.sub(r'(^|\s+)([a-dA-D][\.\)]+)', r'\n\2 ', text)
        
        # Also split if we see a marker with a space but in a pattern like " a. Solo c. Madura"
        # We look for " [marker] "
        text = re.sub(r'(\s+)([a-dA-D])[\.\s\)]+(\s+)', r'\n\2. \3', text)
        
        # Collapse multiple spaces but keep newlines
        text = re.sub(r'[ \t]+', ' ', text)
        return text.strip()

class QuestionParser:
    def parse(self, raw_text: str) -> List[Dict[str, Any]]:
        # 1. Pre-normalize
        text = TextNormalizer.normalize_string(raw_text)
        
        # 2. Tokenize by lines
        lines = [l.strip() for l in text.split("\n") if l.strip()]
        
        questions = []
        curr_q = None
        pending_prefix = ""
        last_q_num = 0
        
        for line in lines:
            line = line.strip()
            if not line: continue

            # 1. Detect Question Start (Number + Text)
            q_match = re.match(r'^(\d+)[\.\s]+(.*)', line)
            
            # 2. Detect Implicit Question (missing number but has markers)
            is_implicit = False
            if not q_match and re.search(r'\?|adalah|sapaan', line, re.IGNORECASE) and len(line) > 10:
                # If we have options, this is likely a NEW question
                if curr_q and curr_q["options"]:
                    is_implicit = True
                # Or if it's the very first block
                elif not curr_q and not questions:
                    is_implicit = True

            if q_match or is_implicit:
                if curr_q:
                    questions.append(curr_q)
                
                if q_match:
                    q_num_val = int(q_match.group(1))
                    q_rem = q_match.group(2).strip()
                    last_q_num = q_num_val
                else:
                    last_q_num += 1
                    q_num_val = last_q_num
                    q_rem = line
                
                # Strict Junk Discard for first questions
                if not questions:
                    pending_prefix = ""
                elif pending_prefix and re.search(r'^[a-dA-D][\.\s\)]', pending_prefix.strip()):
                    pending_prefix = ""
                
                curr_q = {
                    "question_number": q_num_val,
                    "question_text": (pending_prefix + " " + q_rem).strip(),
                    "options": {}
                }
                pending_prefix = ""
                continue

            # 3. Check for Option marker (a., b., c., d.)
            opt_match = re.match(r'^([a-dA-D])[\.\s\)]+\s*(.*)', line, re.IGNORECASE)
            if opt_match and curr_q:
                opt_key = opt_match.group(1).lower()
                opt_val = opt_match.group(2).strip()
                curr_q["options"][opt_key] = opt_val
                continue
            
            # 4. Handle continuation
            if curr_q:
                if curr_q["options"]:
                    last_opt_key = sorted(curr_q["options"].keys())[-1]
                    # If line looks like a question snippet, start buffering it as prefix for NEXT
                    if re.search(r'\?|adalah|sapaan|suku bangsa|manakah|berikut', line, re.IGNORECASE):
                        pending_prefix = (pending_prefix + " " + line).strip()
                    else:
                        # Append to last option
                        existing_val = curr_q["options"][last_opt_key]
                        curr_q["options"][last_opt_key] = (existing_val + " " + line).strip()
                else:
                    # Append to question text
                    curr_q["question_text"] = (curr_q["question_text"] + " " + line).strip()
            else:
                # Discard orphaned options as prefixes
                if not opt_match:
                    pending_prefix = (pending_prefix + " " + line).strip()

        if curr_q:
            questions.append(curr_q)

        # 3. Final polish and filtering
        result = []
        for q in questions:
            # Clean question text
            text = q["question_text"]
            
            # 1. Join hyphenated words (e.g., "kali- mat" -> "kalimat")
            text = re.sub(r'(\w+)-\s+(\w+)', r'\1\2', text)
            
            # 2. Collapse whitespace
            text = re.sub(r'\s+', ' ', text).strip()
            
            # 3. Final punctuation
            if text:
                text = re.sub(r'\.{2,}$', '.', text) # Fix multiple trailing dots
                if not any(text.endswith(p) for p in ['.', '?', '!']):
                    text += "."

            # Clean options similarly
            clean_options = {}
            for k, v in q["options"].items():
                v = re.sub(r'(\w+)-\s+(\w+)', r'\1\2', v)
                # Cleanup leading dots/punc from OCR noise
                v = re.sub(r'^[\.\s,]+', '', v)
                # Remove trailing page numbers (common at bottom of page)
                v = re.sub(r'\s+\d+$', '', v)
                clean_options[k] = re.sub(r'\s+', ' ', v).strip()
            
            if len(clean_options) >= 2:
                # If question text is empty (OCR failed to get the line), 
                # use a placeholder or at least show the options
                final_text = text if text else "[Question text not found]"
                result.append({
                    "question_text": f"{q['question_number']}. {final_text}",
                    "options": clean_options
                })

        return result

class OCRProcessor:
    def __init__(self):
        self.preprocessor = ImagePreprocessor()
        self.ocr = OCRExtractor()
        self.parser = QuestionParser()

    def process(self, image_bytes: bytes) -> Dict[str, Any]:
        image = Image.open(io.BytesIO(image_bytes))
        image_np = self.preprocessor.preprocess(image)

        raw_text, avg_confidence = self.ocr.extract_text(image_np)

        if not raw_text:
            return {
                "success": False,
                "questions": [],
                "ocr": {"raw_text": "", "clean_text": ""}
            }

        questions = self.parser.parse(raw_text)

        return {
            "success": True,
            "avg_confidence": avg_confidence,
            "ocr": {
                "raw_text": raw_text,
                "clean_text": raw_text
            },
            "questions": questions
        }

# def run_ocr(file: io.BytesIO, lang: str = "id", attempt: int = 1) -> Dict[str, Any]:
#     processor = OCRProcessor()
#     image_bytes = file.read()
#     file.seek(0)

#     result = processor.process(image_bytes)

#     return {
#         "source_id": "auto",
#         "ocr": result.get("ocr", {}),
#         "questions": result.get("questions", []),
#         "meta": {
#             "attempt": attempt,
#             "avg_confidence": result.get("avg_confidence", 0.0),
#             "total_questions": len(result.get("questions", []))
#         }
#     }
def run_ocr(file: io.BytesIO, lang: str = "id", attempt: int = 1) -> Dict[str, Any]:
    processor = OCRProcessor()
    image_bytes = file.read()
    file.seek(0)

    result = processor.process(image_bytes)

    formatted_questions = []

    for q in result.get("questions", []):
        raw_qtext = q.get("question_text", "").strip()

        # Extract question number safely (ONLY formatting)
        q_no = None
        q_text = raw_qtext
        m = re.match(r'^(\d+)\.\s*(.*)', raw_qtext)
        if m:
            q_no = int(m.group(1))
            q_text = m.group(2).strip()

        raw_options = q.get("options", {})
        choices = {k.upper(): v for k, v in raw_options.items()}

        q_type = "MULTIPLE_CHOICE" if len(choices) >= 2 else "ESSAY"

        formatted_questions.append({
            "question_no": q_no,
            "type": q_type,
            "question_text": q_text,
            "choices": choices
        })

    return {
        "source_id": "auto",
        "ocr": result.get("ocr", {}),
        "questions": formatted_questions,
        "meta": {
            "engine": "paddleocr",
            "parser_version": "v1",
            "attempt": attempt,
            "avg_confidence": result.get("avg_confidence", 0.0),
            "total_questions": len(formatted_questions)
        }
    }
